# -*- coding: utf-8 -*-
"""glassDoor_webDev.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14IGhyZ7fpCP6yYPEZckrvwHW9C3KZl_T
"""

#Importing libraries :
import numpy as np
import pandas as pd
from bs4 import BeautifulSoup
import requests

#Getting the base url
base_url = "https://www.glassdoor.com/Job/united-states-web-developer-jobs-SRCH_IL.0,13_IN1_KO14,27_IP"

url = base_url + "1"
res = requests.get(url)
soup = BeautifulSoup(res.content,"html.parser")

job_listing = soup.findAll("li",attrs={"class","react-job-listing"})

i = 5

#Job title
job_listing[i]["data-normalize-job-title"]

#Job location
soup.findAll("li",attrs={"class","react-job-listing"})[i]["data-job-loc"]

#Is easy apply :
job_listing[1]["data-id"]

#Company Name
soup.findAll("a",attrs={"class","e1n63ojh0"})[i].text

#salaries
soup.findAll("span",attrs={"class","e1wijj240"})[7].text.split("(")[0]

#Company rating
soup.findAll("a",attrs={"class":"eigr9kq1"})[i].span.text

#The main function to get the data from the base url
def get_data(base_url):
  job_title = []
  job_location = []
  easy_apply = []
  company_name = []
  salaries = []
  company_rating = []
  job_role =[]
  id = []
  for j in range(1,31):
    url = base_url + str(j)
    res = requests.get(url)
    soup = BeautifulSoup(res.content,"html.parser")
    job_listing = soup.findAll("li",attrs={"class","react-job-listing"})
    company_data = soup.findAll("a",attrs={"class","e1n63ojh0"})
    salary = soup.findAll("span",attrs={"class","e1wijj240"})
    rating = soup.findAll("span",attrs={"class":"e1cjmv6j0"})
    role = soup.findAll("a",attrs={"class":"eigr9kq1"})
    for i in range(len(job_listing)):
      id.append(job_listing[i]["data-id"])
      try:
        job_title.append(job_listing[j]["data-normalize-job-title"])
      except:
        job_title.append("N/A")
      try:
        job_location.append(job_listing[i]["data-job-loc"])
      except:
        job_location.append("N/A")
      try:
        easy_apply.append(job_listing[i]["data-is-easy-apply"])
      except:
        easy_apply.append("N/A")
      try:
        company_name.append(company_data[i].text)
      except:
        company_name.append("N/A")
      try:
        salaries.append(salary[i].text.split("(")[0])
      except:
        salaries.append("N/A")
      try:
        company_rating.append(rating[i].text)
      except:
        company_rating.append("N/A")
      try:
        job_role.append(role[i].span.text)
      except:
        job_role.append("N/A")
  return job_title,job_location,easy_apply,company_name,salaries,company_rating,job_role,id

job_title,job_location,easy_apply,company_name,salaries,company_rating,job_role,id = get_data(base_url)

i = range(1,len(job_title)+1)
df = pd.DataFrame({"id":id,"job_title":job_title,"job_role":job_role,"job_location":job_location,"easy_apply":easy_apply,"company_name":company_name,"salaries":salaries,"company_rating":company_rating,},index=i)

df.rename(columns = {'salaries':'salary'}, inplace = True)

